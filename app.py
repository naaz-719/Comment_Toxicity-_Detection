# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qRHJbP3yP8MI3FNVckwecTxVpDxqf51U
"""

from google.colab import drive
import os

# Mount your Google Drive
drive.mount('/content/drive')

# Set the path to your project folder
project_folder = '/content/drive/My Drive/Comment_Toxicity_Project/'

# Change the current working directory to your project folder
os.chdir(project_folder)



import streamlit as st
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle
import re
import os
import io
import time
import altair as alt
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# --- Custom CSS for a Netflix-like dark theme ---
def set_netflix_style():
    """Applies custom CSS for a dark, professional theme."""
    st.markdown(
        """
        <style>
        .stApp {
            background-color: #141414; /* Netflix-like dark background */
            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
            color: #E5E5E5; /* Light gray text for contrast */
        }
        h1, h2, h3, h4, h5, h6 {
            color: #FFFFFF; /* White headings */
            text-align: center;
            font-weight: 500;
        }
        .stButton>button {
            border: none;
            border-radius: 4px;
            color: #FFFFFF;
            background-color: #E50914; /* Netflix red */
            padding: 10px 20px;
            font-weight: bold;
            transition: all 0.2s ease-in-out;
        }
        .stButton>button:hover {
            background-color: #B20710;
        }
        .stFileUploader>button {
            background-color: #E50914; /* Netflix red */
            border-radius: 4px;
            color: white;
            padding: 10px 20px;
        }
        .st-emotion-cache-1c0f4u5 {
            border: 1px solid #333333; /* Darker border for containers */
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            background-color: #1a1a1a; /* Slightly lighter than background */
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }
        .st-emotion-cache-12ttz3k {
            border: 2px solid #222222;
            border-radius: 8px;
            padding: 20px;
            background-color: #1a1a1a;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }
        .st-emotion-cache-1c0f4u5 h2, .st-emotion-cache-12ttz3k h2 {
            color: #FFFFFF;
        }
        .stTextInput>div>div>input, .stTextarea>div>textarea {
            background-color: #222222;
            color: #FFFFFF;
            border: 1px solid #333333;
            border-radius: 4px;
        }
        .st-emotion-cache-17l029s {
            background-color: #222222;
            color: #FFFFFF;
        }
        .st-emotion-cache-1v0609 {
            color: #FFFFFF;
        }
        .st-emotion-cache-1c7y3z4 .st-emotion-cache-4c70d4 {
            color: #6c6c6c;
        }
        .st-emotion-cache-6q9sum a {
            color: #E50914;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

# --- FIX: ADD THIS SECTION TO DOWNLOAD ALL NECESSARY NLTK DATA ---
nltk.download('punkt')
nltk.download('stopwords')
# The following is likely not needed for this code, but included for completeness if `punkt_tab` is ever required.
try:
    nltk.data.find('tokenizers/punkt/english.pickle')
except nltk.downloader.DownloadError:
    nltk.download('punkt_tab')

# --- Helper Functions ---
@st.cache_resource
def load_resources():
    model_path = '/content/drive/MyDrive/Comment_Toxicity_Project/toxicity_model.keras'
    tokenizer_path = '/content/drive/MyDrive/Comment_Toxicity_Project/tokenizer.pickle'

    try:
        model = tf.keras.models.load_model(model_path)
        with open(tokenizer_path, 'rb') as handle:
            tokenizer = pickle.load(handle)
        return model, tokenizer
    except FileNotFoundError as e:
        st.error(f"Error: Model or tokenizer file not found. Please ensure they are at the specified path. {e}")
        return None, None

def preprocess_text(text, tokenizer, max_len=200):
    """Preprocesses a single comment for prediction."""
    text = str(text) # Ensure the input is a string
    text = text.lower()
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'[^a-z0-9\s]', '', text)
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [w for w in tokens if w not in stop_words and len(w) > 1]
    preprocessed_text = " ".join(filtered_tokens)

    sequence = tokenizer.texts_to_sequences([preprocessed_text])
    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')
    return padded_sequence

def predict_toxicity(text, model, tokenizer, max_len=200):
    """Predicts toxicity for a given text."""
    if model is None or tokenizer is None:
        return "N/A"

    padded_sequence = preprocess_text(text, tokenizer, max_len)
    prediction = model.predict(padded_sequence, verbose=0)[0][0]
    return "Toxic" if prediction > 0.5 else "Not Toxic"

# --- Main Streamlit App ---
def main():
    set_netflix_style()

    st.markdown("<h1 style='text-align: center;'>Deep Learning Comment Toxicity Detection ðŸ’¬</h1>", unsafe_allow_html=True)

    model, tokenizer = load_resources()

    st.sidebar.header('Prediction Options')
    prediction_type = st.sidebar.radio("Select Prediction Type", ('Real-Time Prediction', 'Bulk Prediction (CSV Upload)'))

    if prediction_type == 'Real-Time Prediction':
        st.subheader('Real-Time Comment Analysis')
        comment = st.text_area("Enter a comment:")

        if st.button('Predict'):
            if comment and model and tokenizer:
                with st.spinner('Analyzing...'):
                    result = predict_toxicity(comment, model, tokenizer)
                st.write("") # Add a small spacer
                if result == "Toxic":
                    st.error(f"âš ï¸ **Prediction:** {result}", icon="ðŸš¨")
                else:
                    st.success(f"âœ… **Prediction:** {result}", icon="ðŸ‘")
            elif not comment:
                st.warning("Please enter a comment to analyze.")

    elif prediction_type == 'Bulk Prediction (CSV Upload)':
        st.subheader('Bulk Comment Analysis from CSV')
        uploaded_file = st.file_uploader("Upload a CSV file", type=['csv'])

        if uploaded_file is not None:
            if model is None or tokenizer is None:
                st.error("Cannot perform bulk prediction as model or tokenizer could not be loaded.")
                return

            try:
                df = pd.read_csv(uploaded_file)
                st.write("Original Data (First 5 Rows):")
                st.dataframe(df.head())

                if 'comment_text' in df.columns:
                    st.write("Processing predictions...")

                    kpi_container = st.empty()
                    chart_container = st.empty()
                    result_container = st.empty()
                    progress_bar = st.progress(0)

                    df['prediction'] = ""

                    total_rows = len(df)
                    for i, row in df.iterrows():
                        comment = row['comment_text']
                        prediction = predict_toxicity(comment, model, tokenizer)
                        df.loc[i, 'prediction'] = prediction

                        progress_bar.progress((i + 1) / total_rows)

                        if (i + 1) % 50 == 0 or (i + 1) == total_rows:
                            with kpi_container.container():
                                st.subheader("Analysis Dashboard")
                                col1, col2, col3 = st.columns(3)
                                total_comments = i + 1
                                toxic_count = df.loc[0:i, 'prediction'].value_counts().get('Toxic', 0)
                                not_toxic_count = df.loc[0:i, 'prediction'].value_counts().get('Not Toxic', 0)
                                with col1:
                                    st.metric("Total Comments", total_comments)
                                with col2:
                                    st.metric("Toxic Comments", toxic_count)
                                with col3:
                                    st.metric("Non-Toxic Comments", not_toxic_count)

                            with chart_container:
                                st.write("Distribution of Comments")
                                counts = df.loc[0:i, 'prediction'].value_counts().reset_index()
                                counts.columns = ['Category', 'Count']
                                chart = alt.Chart(counts).mark_bar().encode(
                                    x=alt.X('Category', sort='-y'),
                                    y='Count',
                                    color=alt.Color('Category', scale=alt.Scale(domain=['Toxic', 'Not Toxic'], range=['#ff4b4b', '#62c161']))
                                ).properties(
                                    title='Comment Toxicity Breakdown'
                                )
                                st.altair_chart(chart, use_container_width=True)

                            result_container.dataframe(df.head(i + 1))

                    progress_bar.empty()
                    st.success("ðŸŽ‰ **Predictions Complete!**")

                    st.write("Predicted Data:")
                    st.dataframe(df)

                    csv = df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="Download Predicted CSV",
                        data=csv,
                        file_name='predictions.csv',
                        mime='text/csv'
                    )
                else:
                    st.error("The uploaded CSV must contain a column named 'comment_text'.")
            except Exception as e:
                st.error(f"An error occurred during file processing: {e}")

if __name__ == '__main__':
    main()

from pyngrok import ngrok
import threading
import time

# Set your ngrok authentication token here
NGROK_AUTH_TOKEN = "31abAm2pogyOKimNihi07rP80Ty_6GHSRdyXzdcx4GVQdVDz4" # Replace with your actual token
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# Terminate any existing ngrok tunnels
ngrok.kill()

# Use threading to run Streamlit in the background
def run_streamlit():
    os.system('streamlit run app.py &>/dev/null&')

threading.Thread(target=run_streamlit, daemon=True).start()

# Wait for a few seconds to let Streamlit start
time.sleep(5)

# Create a public URL using ngrok on port 8501 (Streamlit's default)
public_url = ngrok.connect(addr='8501', proto='http')
print("Your Streamlit app is ready! Open this URL to view it:")
print(public_url)
